{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbe93dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all necerssary libraries\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium_stealth import stealth\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a281673b",
   "metadata": {},
   "source": [
    "Decided to scrap the glassdoor job board to get insights into the demand for Power Bi versus Tableau in the global analytics job market. The scrapper will pretty much work like the myjobmag scrapper, upon isnpection of the website's HTML structure, once you search a job keyword, say 'Business Intelligence Analyst', you get redirected to a results page populated with several job cards. To get access to the full job description of the job, you have to click on the job card, which dynamically loads a window on the right with the full details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cda7926b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to initialize the browser\n",
    "\n",
    "def init_driver():\n",
    "#set up the browser using the options object\n",
    "\n",
    "    options=webdriver.ChromeOptions()\n",
    "    options.add_argument('--start-maximized')\n",
    "    options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "    options.add_experimental_option('excludeSwitches',['enable_automation'])\n",
    "    options.add_experimental_option('useAutomationExtension','False')\n",
    "\n",
    "    driver = webdriver.Chrome(\n",
    "        service=Service(ChromeDriverManager().install()),\n",
    "        options=options\n",
    ")   \n",
    "    stealth (driver,\n",
    "        languages=[\"en-US\", \"en\"],\n",
    "        vendor=\"Google Inc.\",\n",
    "        platform=\"Win32\",\n",
    "        webgl_vendor=\"Intel Inc.\",\n",
    "        renderer=\"Intel Iris OpenGL Engine\",\n",
    "        fix_hairline=True,\n",
    "        )\n",
    "    return driver\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b41a027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming... 0 jobs already scraped.\n"
     ]
    }
   ],
   "source": [
    "#adding the resume feature, if a job has already been scrapped, the scrapper will skip it\n",
    "\n",
    "scraped_links = set()\n",
    "\n",
    "if os.path.exists(\"glassdoor_data.csv\"):\n",
    "    with open(\"glassdoor_data.csv\", \"r\", encoding=\"utf-8\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            scraped_links.add(row[\"link\"])\n",
    "\n",
    "print(f\"Resuming... {len(scraped_links)} jobs already scraped.\")\n",
    "\n",
    "# append mode, so as not to overide data already in the csv\n",
    "csv_file = open(\"glassdoor_data.csv\", \"a\", newline=\"\", encoding=\"utf-8\")\n",
    "writer = csv.DictWriter(csv_file, fieldnames=[\"title\", \"description\", \"link\"])\n",
    "\n",
    "# Write header only if file is empty\n",
    "if os.stat(\"glassdoor_data.csv\").st_size == 0:\n",
    "    writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1551d0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More jobs have been loaded 1 times\n",
      "More jobs have been loaded 2 times\n",
      "More jobs have been loaded 3 times\n",
      "More jobs have been loaded 4 times\n",
      "More jobs have been loaded 5 times\n",
      "More jobs have been loaded 6 times\n",
      "More jobs have been loaded 7 times\n",
      "More jobs have been loaded 8 times\n",
      "More jobs have been loaded 9 times\n",
      "More jobs have been loaded 10 times\n",
      "More jobs have been loaded 11 times\n",
      "More jobs have been loaded 12 times\n",
      "More jobs have been loaded 13 times\n",
      "More jobs have been loaded 14 times\n",
      "More jobs have been loaded 15 times\n",
      "More jobs have been loaded 16 times\n",
      "More jobs have been loaded 17 times\n",
      "More jobs have been loaded 18 times\n",
      "More jobs have been loaded 19 times\n",
      "More jobs have been loaded 20 times\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     30\u001b[39m href=element.get_attribute(\u001b[33m'\u001b[39m\u001b[33mhref\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     31\u001b[39m job_links.append(href)\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43muniform\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m6\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "#initialize the driver\n",
    "driver=init_driver()\n",
    "base_url=('https://www.glassdoor.com/Job/jobs.htm?sc.occupationParam=power+bi%2C+tableau&sc.locationSeoString=United+States&locId=1&locT=N')\n",
    "driver.get(base_url)\n",
    "time.sleep(random.uniform(4,6))\n",
    "\n",
    "#Pause for manual CAPTCHA solving\n",
    "input(\"Please solve the CAPTCHA manually in the browser window, then press Enter to continue...\")\n",
    "\n",
    "click_count=0\n",
    "while click_count<15: #only scrape the job cards in the first 20 'pages'\n",
    "    try:\n",
    "        show_more_button=WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"button[data-test='load-more']\")))\n",
    "        driver.execute_script(\"arguments[0].scrollIntoView();\", show_more_button)\n",
    "        time.sleep(random.uniform(4,6))\n",
    "        show_more_button.click()\n",
    "        click_count += 1\n",
    "        print(f'More jobs have been loaded {click_count} times')\n",
    "    except Exception as e:\n",
    "        print(f'Reason for failure {e}')\n",
    "        time.sleep(random.uniform(1,2))\n",
    "        driver.find_element(By.CSS_SELECTOR, \"button[data-test='load-more']\").click()\n",
    "\n",
    "\n",
    "#after loading all those jobs-by clicking more 20 times, now find the href elements in the html\n",
    "job_links=[]\n",
    " \n",
    "link_elements = driver.find_elements(By.CSS_SELECTOR, \"a[data-test='job-title']\")\n",
    "for element in link_elements:\n",
    "    href=element.get_attribute('href')\n",
    "    job_links.append(href)\n",
    "    time.sleep(random.uniform(4,6))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43238bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, link in enumerate(job_links):\n",
    "    try:\n",
    "        driver.get(link)\n",
    "        time.sleep(random.uniform(3, 5))\n",
    "\n",
    "        #click the show button\n",
    "        try:\n",
    "            show_more = WebDriverWait(driver, 5).until(\n",
    "                EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[data-test='show-more-cta']\"))\n",
    "            )\n",
    "            show_more.click()\n",
    "            time.sleep(2)\n",
    "        except:\n",
    "            print(\" Show more not found on page\")\n",
    "\n",
    "        # Get job title\n",
    "        try:\n",
    "            title = driver.find_element(By.CSS_SELECTOR, \"h1.heading_Heading__BqX5J\").text.strip()\n",
    "        except:\n",
    "            title = \"N/A\"\n",
    "\n",
    "        # Get job description- the paragraphs are all stored in different div containers\n",
    "        try:\n",
    "            container = driver.find_element(By.CLASS_NAME, \"JobDetails_jobDescription__uW_fK\")\n",
    "            description = container.text.strip()\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Scrapping failed: {e}\")\n",
    "            description = \"N/A\"\n",
    "\n",
    "\n",
    "        writer.writerow({\n",
    "            \"title\": title,\n",
    "            \"description\": description,\n",
    "            \"link\": link\n",
    "        })\n",
    "        csv_file.flush()\n",
    "\n",
    "        print(f\"Successfully Scraped: {title}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"There us and error scraping this link {link}: {e}\")\n",
    "        continue\n",
    "\n",
    "    time.sleep(random.uniform(2, 4))\n",
    "\n",
    "driver.quit()\n",
    "csv_file.close()\n",
    "print(\"Finished scraping Glassdoor jobs!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c589be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrap_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
